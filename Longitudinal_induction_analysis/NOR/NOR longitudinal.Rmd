---
title: "NOR"
output:
  pdf_document: default
  html_document: default
date: '2022-12-05'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Load data
```{r}
#setwd("~/Documents/TDP control files/Longitudinal induction analysis/NOR/")
# Loading
library(pacman)
p_load(readxl, tidyverse)
p_load(broom, ggsignif, multcomp, emmeans, DescTools)
# xlsx files
df <- read_excel("NOR_longitudinal_data.xlsx")

```




Data set where participants not completing all data collection time points are sorted out

```{r}
# Determine the weeks each participant should have
required_weeks <- df %>% 
  distinct(Week) %>% 
  pull()

# Count the number of weeks each participant has data for
participant_week_counts <- df %>%
  group_by(ID) %>%
  summarize(week_count = n_distinct(Week))

# Identify participants with data for all required weeks
complete_participants <- participant_week_counts %>%
  filter(week_count == length(required_weeks)) %>%
  pull(ID)

# Filter the dataset to include only complete participants
df_complete <- df %>%
  filter(ID %in% complete_participants)

# View the new dataset
head(df_complete)
```

Divide dataset up into phases with identical objects, and novel object

```{r}
Identical_cond <-  df_complete %>% filter(Condition == "Hab")
Novel_cond<-  df_complete %>% filter(Condition == "NovRGHT"| Condition =="NovLFT")

```

## Novel object condition

Calculating preference index for novel object over familiar object

https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3332351/ 

In Wang et al.â€™s research (2007), they applied a measure of cognitive function through the Preference Index. This is a ratio of the amount of time spent exploring any one of the two objects in training phase (A or B) or the novel one in test phase (C) over the total time spent exploring both objects, i.e., A or B/(B + A) * 100 (%) in the training session and B or C/(B + C) * 100 (%) in the test phase. Therefore, a preference index above 50% indicates novel object preference, below 50% familiar object preference, and 50% no preference (Hammond et al. 2004).

```{r}
Novel_left <-  df_complete %>% filter(Condition =="NovLFT")
Novel_right<-  df_complete %>% filter(Condition == "NovRGHT")

#use this for full sample in df2 instead, for LMM approach
#Novel_left <-  df %>% filter(Condition =="NovLFT")
#Novel_right<-  df %>% filter(Condition == "NovRGHT")


# calculating DR_ index as (time novel  / (time novel + time familiar)*100)

Novel_right<- Novel_right %>% mutate(DR_index=((Novel_right$`In zone ContactZone_right  cumulative s`/(Novel_right$`In zone ContactZone_right  cumulative s`+Novel_right$`In zone ContactZone_left cumulative s`))*100))
Novel_left<- Novel_left %>% mutate(DR_index=((Novel_left$`In zone ContactZone_left cumulative s`/(Novel_left$`In zone ContactZone_left cumulative s`+Novel_left$`In zone ContactZone_right  cumulative s`))*100))

df2 <- rbind(Novel_left,Novel_right)

```



#Repeated measures ANOVA
```{r}
df2$ID <- as.factor(df2$ID)

df2$Week <- factor(df2$Week , levels = c("Preinduction","1st week post induction","2nd week post induction"))


#for getting an anova object that can be used for post-hoc
p_load(afex)
aov_anova <- aov_car(DR_index ~ Week+ Error(ID /Week), data=df2)
summary(aov_anova)

#post-hoc
p_load(emmeans)
ph<-emmeans(aov_anova, pairwise ~ Week, conf.level = 0.95)
ph
confint(ph)  #for confidence intervals

test(ph) # for p values


```


plot

```{r}

cbbPalette <- c("#fcfdbf", "#feca8d", "#D67236", "#f1605d", "#9e2f7f", "#440f76")

p_load(ggbeeswarm, ggsignif)

ggplot(df2, aes(x = Week, y = DR_index)) +
  geom_beeswarm(data = df2, size = 2.5, aes(color = ID)) +
#  geom_dotplot(aes(fill = ID, color = ID), binaxis = 'y', binwidth = 1,
#               method = "histodot", stackratio = 1, dotsize = 0.5,
#               stackgroups = TRUE, stackdir = "down", position = position_nudge(x = -.1)) +
#  scale_fill_manual(values = cbbPalette) +
#  scale_colour_manual(values = cbbPalette) +
  ylab("DR_index") +
  xlab("Timepoint") +
  geom_signif(comparisons = list(c("Preinduction", "1st week post induction")),
              map_signif_level = TRUE,
              y_position = 120,
              annotations = c("ns")) +
  geom_signif(comparisons = list(c("Preinduction", "2nd week post induction")),
              map_signif_level = TRUE,
              y_position = 110,
              annotations = c("ns")) +
  geom_signif(comparisons = list(c("1st week post induction", "2nd week post induction")),
              map_signif_level = TRUE,
              y_position = 100,
              annotations = c("ns")) +
  geom_crossbar(stat = "summary", fun = mean, width = 0.2, fatten = 1.5) +
  geom_errorbar(data = df2, stat = "summary", fun.data = mean_se, width = 0.1, position = "dodge") +
  theme(text = element_text(size = 13))


```



```{r}
#Loading packages for linear mixed effects modelling
library(lmerTest)
library(lme4)

#creating a linear model of the same variables as included in the anova
m_anova <-lmer(DR_index ~  Week + (1|ID), data=df2)
summary(m_anova)

# Obtain estimated marginal means
emmeans_results <- emmeans(m_anova, ~ Week)

# Perform pairwise comparisons
pairwise_results <- contrast(emmeans_results, method = "pairwise")

# Display the results
summary(pairwise_results)

#bonferroni
pwc <- pairs(emmeans_results, adjust = "bon")
pwc
```
Assumption checks for this approach

```{r}
#1. normality of residuals
# Fit the model
m_anova <- lmer(periphery_preference ~ Week + (1|ID), data = df, na.action = na.omit)

# Extract residuals
residuals <- residuals(m_anova)

# Q-Q plot for normality
qqnorm(residuals)
qqline(residuals)

#2. homoscedasticity (the same as homogeneity of variance)
# Residuals vs Fitted plot
plot(fitted(m_anova), residuals)
abline(h = 0, col = "red")


#3. Independence of Residuals

#Since this is a repeated measures design, you have accounted for within-subject correlation by including random effects. Ensure that there are no obvious patterns in the residuals versus time.

#4 Random Effects Structure:

#The random effects (e.g., intercepts and slopes for each subject) should be normally distributed. This can be checked by examining the distribution of the random effects.

# Extract random effects
ranef(m_anova)

# Check distribution of random effects
qqnorm(ranef(m_anova)$ID[,1])
qqline(ranef(m_anova)$ID[,1])

#5 Linearity:

#The relationship between the predictor variables and the response variable should be linear. This can be assessed by plotting the fitted values against the predictor variables.

# Plot fitted values vs predictors
plot(df$Week, fitted(m_anova))


```


# T-test

Data set where participants not completing all data collection time points are sorted out
```{r}
# Filter out so data is only for the first two weeks
TwoWeeks_df <- df %>% filter(Week == "Preinduction" | Week == "1st week post induction")

```

#Filter out subjects that did not complete
```{r}

# Determine the weeks each participant should have
required_weeks <- TwoWeeks_df %>% 
  distinct(Week) %>% 
  pull()

# Count the number of weeks each participant has data for
participant_week_counts <- TwoWeeks_df %>%
  group_by(ID) %>%
  summarize(week_count = n_distinct(Week))

# Identify participants with data for all required weeks
complete_participants <- participant_week_counts %>%
  filter(week_count == length(required_weeks)) %>%
  pull(ID)

# Filter the dataset to include only complete participants
df_complete <- TwoWeeks_df %>%
  filter(ID %in% complete_participants)

# View the new dataset
head(df_complete)
```

```{r}
df_complete$ID <- as.factor(df_complete$ID)
df_complete$Week <- factor(df_complete$Week , levels = c("Preinduction","1st week post induction"))

```

```{r}
Identical_cond <-  df_complete %>% filter(Condition == "Hab")
Novel_cond<-  df_complete %>% filter(Condition == "NovRGHT"| Condition =="NovLFT")

```


```{r}
Novel_left <-  df_complete %>% filter(Condition =="NovLFT")
Novel_right<-  df_complete %>% filter(Condition == "NovRGHT")


# calculating DR_ index as (time novel  / (time novel + time familiar)*100)

Novel_right<- Novel_right %>% mutate(DR_index=((Novel_right$`In zone ContactZone_right  cumulative s`/(Novel_right$`In zone ContactZone_right  cumulative s`+Novel_right$`In zone ContactZone_left cumulative s`))*100))
Novel_left<- Novel_left %>% mutate(DR_index=((Novel_left$`In zone ContactZone_left cumulative s`/(Novel_left$`In zone ContactZone_left cumulative s`+Novel_left$`In zone ContactZone_right  cumulative s`))*100))

df2 <- rbind(Novel_left,Novel_right)

```



## novelty preference
```{r}

by(df2$DR_index, df2$Week, shapiro.test)

# Perform paired t-test
t_test_result <- t.test(DR_index ~ Week, data = df2, paired = TRUE)

# Print the result of the t-test
print(t_test_result)

# Extract the p-value from the test result
p_value <- t_test_result$p.value
```

```{r}
# Function to convert p-value to significance annotations
get_significance_label <- function(p_value) {
  if (p_value < 0.001) {
    return("***")
  } else if (p_value < 0.01) {
    return("**")
  } else if (p_value < 0.05) {
    return("*")
  } else {
    return("ns")
  }
}
```


```{r}
p_load(ggbeeswarm, ggsignif)
# Get the significance label for the paired t-test p-value
significance_label <- get_significance_label(p_value)

ggplot(df2, aes(x = Week, y = DR_index)) +
  geom_beeswarm(data = df2, size = 2.5, aes(color = ID)) +
  ylab("DR_index (novelty preference)") +
  xlab("Timepoint") +
  geom_signif(comparisons = list(c("Preinduction", "1st week post induction")),
              map_signif_level = TRUE,
              annotations = significance_label) +
  geom_crossbar(stat = "summary", fun = mean, width = 0.2, fatten = 1.5) +
  geom_errorbar(data = df2, stat = "summary", fun.data = mean_se, width = 0.1, position = "dodge") +
  theme(text = element_text(size = 13))
```